# prompts.yaml

suggest_semantic_columns: |
  Analyze the following table schema and sample data to identify columns containing free-form text suitable for semantic search (embedding). Semantic search is used for finding similar descriptions, understanding meaning, or searching based on concepts rather than exact values.

  Table Name: {table_name}

  Schema (Columns and Types - Inferred):
  {schema_str}

  Sample Data (First 5 Rows):
  {df_head_str}

  Identify the column names from the schema list that contain natural language text, descriptions, notes, or comments that would be valuable for semantic search. Exclude IDs, numerical values, dates, codes, categories (unless the categories themselves have descriptive names), or URLs unless the URL text itself is descriptive.

  Respond ONLY with a valid JSON list of strings containing the suggested column names. Example: ["product_description", "customer_review_text"]
  If no columns seem suitable, respond with an empty JSON list: []

  Suggested Columns JSON:

# Used by _route_query (structured output) and route_query_wrapper
route_query_structured: |
  Analyze the context and user query to determine the best approach.

  Database Schema:
  {schema}
  {sample_data}
  User Query:
  "{user_query}"

  Carefully consider the query's intent:
  - Choose "SQL" if the query requires precise data retrieval, filtering, aggregation (counts, sums, averages), or specific values matching the schema columns.
  - Choose "SEMANTIC" if the query asks for descriptions, meaning, similarity, or information likely found in unstructured text columns (like product descriptions, notes, etc.).

  Respond ONLY with a valid JSON object containing a single key "query_type" whose value is either the string "SQL" or the string "SEMANTIC". Example: {{"query_type": "SQL"}}

# Base prompt for SQL generation
generate_sql_base: |
  You are an expert SQL generator for SQLite.

  **Inputs:**
  - **schema** (JSON): {schema}
  - **sample_data** (sample rows): {sample_data}
  - **user_query**: {user_query}
  - **augmented_keywords** (list): {augmented_keywords}

  **Rules:**
  1. Generate a valid SQLite query and end with a semicolon.
  2. Unless specically instructed to do so, do NOT prefix table names with the database ID or filename (e.g., use 'FROM table_name' not 'FROM db_id.table_name').
  3. SELECT either `*` or only the columns needed to answer the question.
  4. Use numeric comparisons without units (e.g. `COUNT < 5`).
  5. For text filter related requests, try to use augmented_keywords and use `column LIKE '%keyword%' COLLATE NOCASE`. Group multiple keywords in an `OR` clause, e.g.: 

     WHERE (LOWER(col) LIKE '%keyword1%' OR LOWER(col) LIKE '%keyword2%')
    
  6. Resolve ties for MIN/MAX via subqueries or ORDER BY … LIMIT ….
  7. Skip ORDER BY/LIMIT unless the question explicitly asks for “top N” or “first/last”.
  8. Do not alter the schema or data.



  **Output:** ONLY the SQL statement (no explanation, no commentary, no markdown).

  

# Addendum for SQL generation retries based on feedback
generate_sql_feedback_syntax_correction: |

  The following SQL query attempt contained a syntax error:
  Incorrect SQL: `{previous_sql}`
  The error reported was: "{error_message}"
  Error: "{feedback}"
  Please provide clear, concise instruction on how to fix or prevent this error.

generate_sql_feedback_schema_issue: |

  The following SQL query attempt failed due to a schema-related issue (e.g., a table or column was not found as named):
  SQL Executed: `{previous_sql}`
  The error reported was: "{error_message}"
  {schema_context_reminder}
  Based on this error and the schema originally provided, please generate a corrected SQL query.
  For example, if the error was "no such table db_name.table_name", ensure you use only "table_name".
  If the error was "no such column x", ensure column "x" exists in the specified table or correct the join condition.

generate_sql_feedback_other_improvement: |

  The following SQL query was previously generated:
  SQL Executed: `{previous_sql}`
  However, it needs improvement. 
  Reason: "{reason_for_improvement}"
  Please generate an improved SQL query that addresses this reason while still answering the original user request based on the provided schema and sample data.

# Final instruction for SQL generation response format
generate_sql_response_format: |

  Respond ONLY with the SQLite query, ending with a semicolon.
  SQLite Query:

# Prompt for validating SQL results
validate_sql_results: |
  You are validating SQL query results.
  User's original query: "{user_query}"
  Executed SQL query: `{executed_sql}`
  Data returned (sample):
  {context_str}

  Does the returned data accurately and completely answer the user's original query? Consider if the filtering, ordering, and selected columns are appropriate.

  Respond ONLY with a valid JSON object with two keys:
  1. "satisfactory": boolean (true if the data answers the query, false otherwise).
  2. "reason": string (if false, a BRIEF explanation of why, e.g., "missing filter for category", "wrong ordering", "needs different columns". If true, this can be an empty string or null).
  Example if unsatisfactory: {{"satisfactory": false, "reason": "The query returned the highest price, but the user asked for the cheapest."}}
  Example if satisfactory: {{"satisfactory": true, "reason": ""}}

# Prompt to check if query is English
check_language: |
  Is the following query primarily written in English? Respond only with YES or NO.

  Query: "{user_query}"

# Prompt to translate a query to English
translate_to_english: |
  Translate the following query accurately into English. Respond ONLY with the English translation.

  Query: "{user_query}"

  English Translation:

# Prompt for summarizing requirements from conversation history
derive_requirements_from_history: |
  You are an expert data assistant. Based on the following conversation history between a user and an assistant, derive a concise summary of the user's real requirements for searching the database. Focus on any specific filters, desired aggregations, or conditions mentioned by the user.

  Conversation History:
  {context}

  Please provide a refined summary of the user's requirements that can be used to generate the best search query for the latest message by the user.
  Refined Requirements:

# Consolidated prompt for refining query, selecting table, and determining route
refine_and_select: |
  You are an expert data analyst assisting a user querying a database with potentially multiple tables. Your primary goal is to determine the correct table and the best way to query it based on the user's request and the available data structure.

  **Inputs:**
  1. Conversation History: {recent_context}
  2. User Query: "{user_query}"
  3. Schema (JSON): {schema}
  4. Sample Data: {sample_data}

  **Steps:**
  1. Read the user’s question.  
  2. Identify which table(s) and columns are needed.  
  3. Rewrite the question into a **refined_query** that precisely names tables/columns and any filters, joins, aggregations, or sort orders.  
  4. Extract any important search terms into **augmented_keywords**.  
  5. Decide whether this should be handled via `"SQL"` or `"SEMANTIC"`.

  **Output:**  
  A single JSON object with exactly three keys:
  - refined_query (string)  
  - augmented_keywords (list of strings)  
  - route ("SQL" or "SEMANTIC")
  Respond ONLY with that JSON object
 
    

# Prompt for generating the final natural language summary
generate_final_summary: |
  Based only on the following retrieved data (which may include SQL results, semantic search snippets, or both), provide a concise and helpful natural language answer to the user's original query. If both SQL and semantic results are present, try to synthesize them. If one or both are empty or irrelevant, state that.

  User Query: "{original_query}"{translated_context}

  Retrieved Data:
  ---
  {summary_context}
  ---

  Answer:

select_database_id: |
  You are a database schema expert. Your task is to identify the SINGLE most relevant database ID to answer the user's query, given a list of databases and their detailed schemas (tables and columns).

  **Instructions:**
  1. Analyze the **User Query** carefully.
  2. Examine the schemas provided under **Available Databases**. Pay close attention to **table names AND column names** within each database ID.
  3. Match keywords, concepts, and entities mentioned in the query to the database that most likely contains the relevant tables and columns.
  4. Respond ONLY with the single database ID string (the top-level key from the schema list) that is the best fit. Do not add any explanation.

  **Available Databases (Schema Details & Sample Data Snippet):**
  
  {schemas_json}
  
  **Available table names:** {db_id_list}
  Please respond with exactly one of these values.


  ** User Query:** {user_query}
